# Big Data Preprocessing of Myocardial Infarction Dataset using Spark-Hadoop Cluster
## Project Overview
This project focuses on building a distributed data processing system using Apache Hadoop and Apache Spark on Fedora virtual machines. It configures hadoop1 as the master node and hadoop2 (Or as many that the user can add) as worker nodes to process the UCI Myocardial Infarction dataset efficiently. By combining Hadoopâ€™s distributed storage and Sparkâ€™s parallel computation, the project enables scalable preprocessing and analysis of healthcare data to support predictive modeling and clinical decision-making
## Project Ojectives and Activities
- ğŸ§  Built a distributed data processing environment using Apache Hadoop and Apache Spark on Fedora virtual machines.
- ğŸ–¥ï¸ Set up two interconnected VMs and configured a network cluster for scalable data handling.
- ğŸ”‘ Implemented passwordless SSH access to enable secure, seamless communication between nodes.
- ğŸ§© Assigned hadoop1 as the master node and hadoop2 as the worker node to support parallel computation.
- ğŸ’» Launched PySpark sessions across the cluster for distributed data processing.
- ğŸ§¹Performed data preprocessing on the UCI Myocardial Infarction dataset, including cleaning, transformation, and feature selection.
- ğŸ“Š Demonstrated scalable analytics in a simulated healthcare data pipeline using Spark and HDFS integration
## Technologies Used
- ğŸ˜ Apache Hadoop â€“ for distributed storage and cluster management
- âš¡ Apache Spark â€“ for parallel data processing and computation
- ğŸ PySpark â€“ for executing Python-based distributed data workflows
- ğŸ§© Fedora Linux â€“ as the base operating system for virtual machines
- ğŸ”‘ SSH (Secure Shell) â€“ for passwordless and secure inter-node communication
- ğŸ—‚ï¸ HDFS (Hadoop Distributed File System) â€“ for scalable data storage and access
## Challenges Faced
- ğŸ’¾ Limited RAM â€” The virtual machines had low memory capacity, which increased the execution time for most Spark and Hadoop commands.
- ğŸŒ Network Configuration Issues â€” Setting up the cluster network was challenging, and an Amazon Network shutdown temporarily disrupted connectivity between nodes.
- ğŸ§ Fedora Navigation Difficulties â€” Navigating and configuring system files in Fedora required additional learning, especially during environment setup and SSH configuration.
## Carry-on Lessons
- ğŸ§© Acquired practical experience in configuring and managing Apache Hadoop and Apache Spark clusters within a Fedora Linux environment.
- ğŸ”‘ Gained proficiency in setting up secure, passwordless SSH communication to facilitate seamless interaction between master and worker nodes.
- ğŸ’¾ Recognized the impact of hardware limitations, particularly limited RAM, on the performance and efficiency of distributed systems.
- ğŸ§° Enhanced skills in network configuration, troubleshooting, and system integration within a clustered architecture.
- ğŸ’» Strengthened command-line and system administration expertise, improving confidence in Linux-based operations.
- ğŸš€ Developed advanced problem-solving and debugging abilities through practical deployment and testing challenges.
- ğŸŒ Deepened understanding of distributed computing principles and their application to scalable data processing.
- ğŸ§® Appreciated the importance of resource planning and optimization for stable and efficient system performance.
- ğŸ”“ Built confidence in leveraging open-source big data tools for research and healthcare data analytics applications.
